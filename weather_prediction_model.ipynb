{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":8049216,"datasetId":4746629,"databundleVersionId":8163190}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n# Download latest version\npath = kagglehub.dataset_download(\"nachiketkamod/weather-dataset-us\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-18T02:51:08.436622Z","iopub.execute_input":"2025-03-18T02:51:08.436973Z","iopub.status.idle":"2025-03-18T02:55:22.873523Z","shell.execute_reply.started":"2025-03-18T02:51:08.436932Z","shell.execute_reply":"2025-03-18T02:55:22.872410Z"}},"outputs":[{"name":"stdout","text":"Mounting files to /kaggle/input/weather-dataset-us...\nPath to dataset files: /kaggle/input/weather-dataset-us\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"IMports\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T02:55:57.741554Z","iopub.execute_input":"2025-03-18T02:55:57.742110Z","iopub.status.idle":"2025-03-18T02:55:58.853018Z","shell.execute_reply.started":"2025-03-18T02:55:57.742079Z","shell.execute_reply":"2025-03-18T02:55:58.851856Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"Train and test data","metadata":{}},{"cell_type":"code","source":"# For setting up the random state\nimport random\nrandom.seed(42)\n\n# Sample dataset (you would replace this with your actual dataset)\ndata = pd.DataFrame({\n    'longitude': np.random.uniform(-180, 180, 1000),\n    'latitude': np.random.uniform(-90, 90, 1000),\n    'precipitation': np.random.uniform(0, 500, 1000),\n    'temperature': np.random.uniform(-30, 50, 1000)  # target variable (could be temperature or any other weather feature)\n})\n\n# Features and target\nX = data[['longitude', 'latitude', 'precipitation']]\ny = data['temperature']\n\n# Train-test split (80% training, 20% testing)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Initialize models","metadata":{}},{"cell_type":"code","source":"# Decision Tree Regressor\ndt_model = DecisionTreeRegressor(random_state=42)\n\n# XGBoost Regressor\nxgb_model = XGBRegressor(random_state=42, n_estimators=100, learning_rate=0.1)\n\n# Random Forest Regressor\nrf_model = RandomForestRegressor(random_state=42, n_estimators=100)\n\n# Linear Regression Model\nlr_model = LinearRegression()\n\n# K-Nearest Neighbors Regressor\nknn_model = KNeighborsRegressor(n_neighbors=5)\n\n# List of models to iterate over\nmodels = [dt_model, xgb_model, rf_model, lr_model, knn_model]\nmodel_names = ['Decision Tree', 'XGBoost', 'Random Forest', 'Linear Regression', 'K-Nearest Neighbors']\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Training model ","metadata":{}},{"cell_type":"code","source":"# Loop to train and evaluate all models\nresults = {}\n\nfor model, name in zip(models, model_names):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    \n    # Calculate the metrics\n    mse = mean_squared_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n    \n    results[name] = {'MSE': mse, 'R2': r2}\n    \n    print(f\"{name} Model Performance:\")\n    print(f\"Mean Squared Error: {mse:.4f}\")\n    print(f\"R-squared: {r2:.4f}\")\n    print(\"-\" * 50)\n\n# Convert results to DataFrame for better visualization\nresults_df = pd.DataFrame(results).T\nimport ace_tools as tools; tools.display_dataframe_to_user(name=\"Model Performance\", dataframe=results_df)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n# Example: Grid Search for Random Forest\nparam_grid = {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]}\ngrid_search = GridSearchCV(rf_model, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\nprint(f\"Best parameters for Random Forest: {grid_search.best_params_}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}